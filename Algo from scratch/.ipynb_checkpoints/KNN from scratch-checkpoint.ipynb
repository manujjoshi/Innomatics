{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80202b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4629a81",
   "metadata": {},
   "source": [
    "### [KNN from scratch](https://medium.com/analytics-vidhya/implementing-k-nearest-neighbours-knn-without-using-scikit-learn-3905b4decc3c)\n",
    "#### So let’s start with the implementation of KNN. It really involves just 3 simple steps:\n",
    "1. Calculate the distance(Euclidean, Manhattan, etc) between a test data point and every training data point. This is to see who is closer and who is far by how much.\n",
    "2. Sort the distances and pick K nearest distances(first K entries) from it. Those will be K closest neighbors to your given test data point.\n",
    "3. Get the labels of the selected K neighbors. The most common label(label with a majority vote) will be the predicted label for our test data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "724ffa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "af3cae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state = 42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae800d1",
   "metadata": {},
   "source": [
    "#### We will define a class ‘KNN’ inside which we will define every essential function that will make our algorithm work. We will be having the following methods inside our class.\n",
    "1. fit: As discussed earlier, it’ll just keep the data with itself, since KNN does not perform any explicit training process.\n",
    "2. Distance: We will calculate Euclidean distance here.\n",
    "3. Predict: This is the phase where we will predict the class for our testing instance using the complete training data. We will implement the 3 stepped process discusses above in this method.\n",
    "4. Score: Finally We’ll have a score method, to calculate the score for our model based on the test data\n",
    "5. What about ‘K’ ?: The most important guy here is K, we will pass ‘K’ as an argument while initializing the object for our KNN class(inside __init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58d7c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "        \n",
    "############################################################\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "############################################################\n",
    "\n",
    "    def distance(self, X1, X2):\n",
    "        distance = scipy.spatial.distance.euclidean(X1, X2)\n",
    "    \n",
    "###########################################################\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        final_output = []\n",
    "        for i in range(len(X_test)):\n",
    "            d = []\n",
    "            votes = []\n",
    "            for j in range(len(X_train)):\n",
    "                dist = scipy.spatial.distance.euclidean(X_train[j] , X_test[i])\n",
    "                d.append([dist, j])\n",
    "            d.sort()\n",
    "            d = d[0:self.k]\n",
    "            for d, j in d:\n",
    "                votes.append(y_train[j])\n",
    "            ans = Counter(votes).most_common(1)[0][0]\n",
    "            final_output.append(ans)\n",
    "            \n",
    "        return final_output\n",
    "    \n",
    "####################################################################\n",
    "    \n",
    "    def score(self, X_test, y_test):\n",
    "        predictions = self.predict(X_test)\n",
    "        return (predictions == y_test).sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6cab4e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.6, 3.6, 1. , 0.2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60fcb676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.1, 2.8, 4.7, 1.2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83d9c61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.192851058647326"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt((4.6 - 6.1)**2 + (3.6 - 2.8)**2 + (1 - 4.7)**2 + (.2 - 1.2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db17a280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.192851058647326"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance = scipy.spatial.distance.euclidean(X_train[0], X_test[0])\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c95899",
   "metadata": {},
   "source": [
    "#### See what’s happening:\n",
    "- We will pass the K while creating an object for the class ‘KNN’.\n",
    "- Fit method just takes in the training data, nothing else.\n",
    "- We used scipy.spatial.distance.euclidean for calculating the distance between two points.\n",
    "- Predict method runs a loop for every test data point, each time calculating distance between the test instance and every training instance. It stores distance and index of the training data together in a 2D list. It then sorts that list based on distance and then updates the list keeping only the K shortest distances(along with their indices) in the list.\n",
    "- It then pulls out labels corresponding to those K nearest data points and checks which label has the majority using Counter. That majority label becomes the label of the test data point.\n",
    "- Score method just compares our test output with their actual output to find the accuracy of our prediction.\n",
    "- Kudos! That’s it. It’s really that simple! Now let’s run our model and test our algorithm on the test data we split apart earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270549e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNN(3)\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)\n",
    "for i in prediction:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be14479",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction == y_test # all predictions are true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba416b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f792033",
   "metadata": {},
   "source": [
    "## `END -----------------------------------------`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
